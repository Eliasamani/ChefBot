import os
import openai
import re
import uuid
import json

from flask import Flask, render_template, request, jsonify, session
from dotenv import load_dotenv

load_dotenv()

app = Flask(__name__)
app.secret_key = "SUPER_SECRET_KEY"  # needed for Flask session usage

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    raise ValueError("No OpenAI API key found. Please set OPENAI_API_KEY in your .env.")

openai.api_key = OPENAI_API_KEY

# ----------------------------------------------------------------
# IN-MEMORY STORES
# ----------------------------------------------------------------

# Maps recipe_id -> full recipe data generated by GPT
RECIPES_STORE = {}

# Maps session_id -> conversation context string
CONVERSATION_STORE = {}

# ----------------------------------------------------------------
# MAIN ROUTES
# ----------------------------------------------------------------

@app.route('/')
def index():
    """
    Render the main page with the ingredient selection UI and chat interface.
    """
    return render_template('index.html')


@app.route('/get_recipes', methods=['POST'])
def get_recipes():
    """
    Generate a list of recipes via GPT, given user-specified ingredients and preferences.
    Returns a JSON array of minimal recipe info (id, title).
    """
    data = request.get_json()
    ingredients = data.get('ingredients', [])
    preferences = data.get('preferences', {})

    if not ingredients:
        return jsonify({'error': 'Please provide some ingredients.'}), 400

    session_id = get_or_create_session_id()

    # Generate recipes with GPT (3 recipes)
    new_recipes = generate_recipes_with_gpt(ingredients, preferences, fresh_call=False)
    if not new_recipes:
        return jsonify({'error': 'No recipes generated by GPT.'}), 404

    # Store each recipe in memory by ID
    minimal_data = []
    for recipe in new_recipes:
        recipe_id = str(uuid.uuid4())[:8]  # short random ID
        recipe['id'] = recipe_id
        RECIPES_STORE[recipe_id] = recipe
        minimal_data.append({
            'id': recipe_id,
            'title': recipe.get('title', 'Untitled Recipe'),
        })

    return jsonify({'recipes': minimal_data})


@app.route('/see_more', methods=['POST'])
def see_more():
    """
    Return full info (title, ingredients, macros, instructions, etc.) for a recipe by ID.
    This does NOT change the conversation context.
    """
    data = request.get_json()
    recipe_id = data.get('recipe_id', '')
    if not recipe_id:
        return jsonify({'error': 'No recipe ID provided.'}), 400

    recipe = RECIPES_STORE.get(recipe_id)
    if not recipe:
        return jsonify({'error': 'Recipe not found.'}), 404

    return jsonify({
        'info': {
            'title': recipe.get('title', 'Untitled'),
            'ingredients': recipe.get('ingredients', []),
            'macros': recipe.get('macros', 'No macros data'),
            'instructions': recipe.get('instructions', 'No instructions'),
            'servings': recipe.get('servings', 2)
        }
    })


@app.route('/chatbot', methods=['POST'])
def chatbot():
    """
    Handles user chat with GPT, plus special commands:

    - "I want new recipes"
      => Clears conversation context, generates fresh recipes, and displays them.

    - "CHOOSE_RECIPE_{id}__SERVINGS_{servings}"
      => Choose a given recipe ID for the specified servings, possibly scaling amounts.

    - If user says "I want a recipe with X and Y", we do a strict GPT call
      that only uses those exact ingredients.

    - Otherwise, normal GPT conversation with context.
    """
    data = request.get_json()
    user_message = data.get('message', '').strip()
    ingredients = data.get('ingredients', [])
    preferences = data.get('preferences', {})

    if not user_message:
        return jsonify({'error': 'No message provided.'}), 400

    session_id = get_or_create_session_id()
    context = CONVERSATION_STORE.get(session_id, "")

    user_message_lower = user_message.lower()

    # ----------------------------------------------------------------
    # SPECIAL COMMAND: "I want new recipes"
    # ----------------------------------------------------------------
    # This should clear the conversation context, generate new recipes, and list them at the top.
    if user_message_lower == 'i want new recipes':
        # Clear conversation context
        CONVERSATION_STORE[session_id] = ""
        context = ""

        new_recipes = generate_recipes_with_gpt(ingredients, preferences, fresh_call=True)
        if not new_recipes:
            return jsonify({'reply': "I'm sorry, I couldn't generate any new recipes.", 'context': context})

        minimal_data = []
        for recipe in new_recipes:
            recipe_id = str(uuid.uuid4())[:8]
            recipe['id'] = recipe_id
            RECIPES_STORE[recipe_id] = recipe
            minimal_data.append({
                'id': recipe_id,
                'title': recipe.get('title', 'Untitled Recipe'),
            })

        return jsonify({
            'reply': "Here are some **brand new** recipes from GPT!",
            'recipes': minimal_data,
            'context': context  # context is now empty
        })

    # ----------------------------------------------------------------
    # SPECIAL COMMAND: "CHOOSE_RECIPE_{id}__SERVINGS_{servings}"
    # ----------------------------------------------------------------
    if user_message_lower.startswith('choose_recipe_'):
        try:
            parts = user_message.split('__SERVINGS_')
            left = parts[0]  # e.g. "CHOOSE_RECIPE_abc123"
            servings_str = parts[1]
            servings = int(servings_str)

            recipe_id = left.split('_')[-1]
            recipe_info = RECIPES_STORE.get(recipe_id)
            if not recipe_info:
                return jsonify({'reply': "Sorry, I couldn't find that recipe in memory.", 'context': context})

            # Scale the recipe if needed
            original_servings = recipe_info.get('servings', 2)
            if servings != original_servings and original_servings > 0:
                scale_factor = servings / original_servings

                scaled_ingredients = []
                for ing in recipe_info.get('ingredients', []):
                    scaled_ingredients.append(scale_ingredient(ing, scale_factor))
                recipe_info['ingredients'] = scaled_ingredients

                if 'macros' in recipe_info:
                    recipe_info['macros'] = scale_macros(recipe_info['macros'], scale_factor)

                recipe_info['servings'] = servings

            # Build a details message to reply with
            reply_msg = generate_recipe_details_msg(recipe_info)

            # We incorporate these details into context for future GPT conversation
            updated_context = context + f"\nCHOSEN_RECIPE_DETAILS:\n{reply_msg}\n"
            CONVERSATION_STORE[session_id] = updated_context

            return jsonify({'reply': reply_msg, 'context': updated_context})
        except Exception as e:
            print("Error parsing CHOOSE_RECIPE command:", e)
            return jsonify({'reply': "Error: invalid recipe choose command.", 'context': context})


    #AnvÃ¤nds inte just nu.
    # ----------------------------------------------------------------
    # If user explicitly says: "I want a recipe with chicken and rice", do strict
    # ----------------------------------------------------------------
    if user_message_lower.startswith("i want a recipe with "):
        # Extract everything after 'with'
        after_with = user_message_lower.replace("i want a recipe with", "").strip()
        # naive approach => split on "and" or ","
        requested_ings = re.split(r'[,\s]*and[,\s]*|,', after_with)
        requested_ings = [x.strip() for x in requested_ings if x.strip()]

        strict_recipes = generate_strict_recipes_with_gpt(requested_ings, preferences)
        if not strict_recipes:
            return jsonify({
                'reply': f"No strict recipes found that only use: {requested_ings}.",
                'context': context
            })

        minimal_data = []
        for recipe in strict_recipes:
            recipe_id = str(uuid.uuid4())[:8]
            recipe['id'] = recipe_id
            RECIPES_STORE[recipe_id] = recipe
            minimal_data.append({
                'id': recipe_id,
                'title': recipe.get('title', 'Untitled Recipe'),
            })

        return jsonify({
            'reply': f"Here are strictly matched recipes with: {', '.join(requested_ings)}",
            'recipes': minimal_data,
            'context': context
        })

    # ----------------------------------------------------------------
    # NORMAL CONVERSATION with GPT (just a chat)
    # ----------------------------------------------------------------
    updated_context = context + f"\nUser: {user_message}\n"
    try:
        gpt_reply = call_gpt_chat(updated_context)
        updated_context += f"Assistant: {gpt_reply}\n"
        CONVERSATION_STORE[session_id] = updated_context
        return jsonify({'reply': gpt_reply, 'context': updated_context})
    except Exception as e:
        return jsonify({'reply': f"An error occurred: {str(e)}", 'context': updated_context})

# ----------------------------------------------------------------
# HELPER FUNCTIONS
# ----------------------------------------------------------------

def get_or_create_session_id():
    """
    Retrieve or create a session_id for the user.
    """
    if 'session_id' not in session:
        session['session_id'] = str(uuid.uuid4())
    return session['session_id']


def call_gpt_chat(context):
    """
    Uses the OpenAI ChatCompletion endpoint to continue the conversation
    based on the context. Returns GPT's reply as text.
    """
    system_instructions = (
        "You are ChefBot, a helpful cooking assistant. "
        "Generate or discuss recipes based on user questions. "
        "If CHOSEN_RECIPE_DETAILS is in the context, you can reference it. "
        "Use JSON or structured text where relevant."
    )

    messages = [
        {"role": "system", "content": system_instructions},
        {"role": "assistant", "content": context},
    ]

    response = openai.chat.completions.create(
        model='gpt-3.5-turbo',
        messages=messages,
        max_tokens=300,
        temperature=0.7,
    )
    return response.choices[0].message.content.strip()


def generate_recipes_with_gpt(ingredients, preferences, fresh_call=False):
    """
    Generates 5 recipes using GPT. We use few-shot style prompts to ensure
    the output is in valid JSON.
    """
    print("\n[DEBUG] generate_recipes_with_gpt() called")
    print(f"[DEBUG] ingredients={ingredients}, preferences={preferences}, fresh_call={fresh_call}")

    #system_instructions = (
    #    "You are ChefBot, a helpful cooking assistant. "
    #    "You provide ONLY valid JSON with keys: title, ingredients, macros, instructions, servings. "
    #    "No extra text outside JSON."
    #)
    
    system_instructions = (
    "You are ChefBot, a helpful and knowledgeable cooking assistant. "
    "Your goal is to generate high-quality, creative, and well-balanced recipes based on user input. "
    "Follow these steps before providing the final JSON response:\n\n"

    "1 **Analyze Ingredients:** Carefully review the given ingredients and think about their compatibility. "
    "Consider common cooking techniques that work well for these ingredients.\n\n"

    "2 **Select a Recipe Style:** Decide if the recipe should be a salad, soup, main dish, or side dish. "
    "Choose based on ingredient suitability and cooking methods.\n\n"

    "3 **Ensure Nutritional Balance:** Make sure the recipe includes a balance of proteins, carbs, and healthy fats. "
    "If an ingredient list lacks a key macronutrient, suggest minor improvements.\n\n"

    "4 **Check Flavor Pairings:** Consider how the ingredients will taste together. "
    "Use herbs, spices, and seasoning to enhance flavors without overpowering the dish.\n\n"

    "5 **Generate a Step-by-Step Cooking Process:** Provide clear, structured cooking instructions. "
    "Ensure that steps follow a logical order and are easy to follow.\n\n"

    "6 **Format the Response as JSON:** Provide ONLY valid JSON with the following keys: "
    "'title', 'ingredients', 'macros', 'instructions', and 'servings'. "
    "DO NOT include explanations, comments, or extra text outside of the JSON response.\n"
)


    # Few-shot examples:
    example_user_1 = "I want new recipes."
    example_assistant_1 = (
        '[\n'
        '  {\n'
        '    "title": "Cheesy Tomato & Onion Bake",\n'
        '    "ingredients": ["2 tomatoes", "1 onion", "1 cup cheese"],\n'
        '    "macros": "Calories: 300, Fat: 15g, Protein: 12g, Carbs: 28g",\n'
        '    "instructions": "1. Preheat oven to 200Â°C. 2. Slice tomatoes and onions. 3. Layer slices in a baking dish, sprinkling cheese between layers. 4. Bake for 20 minutes until cheese is melted and golden.",\n'
        '    "servings": 2\n'
        '  }\n'
        ']'
    )

    example_user_2 = "I want new recipes."
    example_assistant_2 = (
        '[\n'
        '  {\n'
        '    "title": "Creamy Mushroom Pasta",\n'
        '    "ingredients": ["200g pasta", "1 cup mushrooms", "1/2 cup cream"],\n'
        '    "macros": "Calories: 450, Fat: 20g, Protein: 15g, Carbs: 55g",\n'
        '    "instructions": "1. Cook pasta until al dente, then drain. 2. SautÃ© mushrooms in a pan until softened. 3. Add cream and simmer for 2-3 minutes. 4. Toss pasta with the sauce, mixing well. 5. Serve hot, optionally garnished with parsley or cheese. etc.",\n'
        '    "servings": 2\n'
        '  }\n'
        ']'
    )

    final_user_prompt = (
        f"I have these ingredients: {', '.join(ingredients)}. "
        f"My preferences are: {preferences}. "
        "Generate exactly 5 recipe ideas in valid JSON array form. \n"
        "Make sure each recipe has a title, ingredients, macros, instructions, everything scaled to 2 servings.\n"
        "No extra text, no extra keys.\n"
    )

    if fresh_call:
        final_user_prompt += "Please ensure these are brand-new recipe ideas."

    messages = [
        {"role": "system", "content": system_instructions},
        {"role": "user", "content": example_user_1},
        {"role": "assistant", "content": example_assistant_1},
        {"role": "user", "content": example_user_2},
        {"role": "assistant", "content": example_assistant_2},
        {"role": "user", "content": final_user_prompt},
    ]

    # Debug
    print("[DEBUG] Final prompt messages for ChatCompletion:")
    for i, msg in enumerate(messages):
        print(f"[{i}] role={msg['role']}, content={msg['content'][:60]}...")

    try:
        response = openai.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=messages,
            max_tokens=1000,
            temperature=0.7,
        )
        response_text = response.choices[0].message.content.strip()
        print("[DEBUG] Raw GPT response:")
        print(response_text)

        recipes = json.loads(response_text)
        if isinstance(recipes, list):
            # Self-Consistency Check
            if any(preferences.values()):
                print(preferences)
                print("[DEBUG] Self-consistency check.")
                verified_recipes = validate_recipes_with_gpt(recipes, preferences)
                return verified_recipes
            else:
                return recipes  # Return as-is if no preferences exist
        
    except Exception as e:
        print("[DEBUG] Error generating recipes with GPT:", e)

    return []


def validate_recipes_with_gpt(recipes, preferences):
    """
    Takes the generated recipes and validates them against user preferences
    by re-feeding them into GPT to confirm compliance.

    - If all recipes are valid, return them as-is.
    - If any recipe is invalid, regenerate new ones.
    - Preserve the original JSON structure.
    """
    system_instructions = (
        "You are an AI assistant verifying that the following recipes strictly adhere "
        "to the user's dietary preferences. If any recipe includes an ingredient that violates "
        "the preferences, mark it as 'is_valid': false.\n"
        "Return the same JSON structure but add an 'is_valid' key (true/false) for each recipe."
        "DO NOT add any extra text or explanationsâONLY return the JSON array."
    )

    validation_prompt = (
        f"The user has these dietary preferences: {preferences}. "
        "Check the following recipes and mark whether they comply.\n"
        f"Recipes: {json.dumps(recipes, indent=2)}"
    )

    print("[DEBUG] Validation Prompt:", validation_prompt)

    messages = [
        {"role": "system", "content": system_instructions},
        {"role": "user", "content": validation_prompt},
    ]

    try:
        response = openai.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=messages,
            max_tokens=1000,
            temperature=0.5,
        )
        response_text = response.choices[0].message.content.strip()

        if not response_text:
            print("[ERROR] GPT returned an empty response for validation.")
            return recipes  # Return original recipes if validation fails

        print("[DEBUG] GPT Validation Response:", response_text)

        validated_recipes = json.loads(response_text)

        if not isinstance(validated_recipes, list):
            print("[ERROR] GPT response is not a valid JSON array.")
            return recipes  # Return original recipes if JSON is malformed

        # Check if all recipes are valid
        all_valid = all(r.get("is_valid", True) for r in validated_recipes)

        if all_valid:
            print("[DEBUG] All recipes are valid. Returning as-is.")
            # Remove 'is_valid' field before returning, to keep original format
            for recipe in validated_recipes:
                recipe.pop("is_valid", None)
            return validated_recipes

        # If some recipes are invalid, regenerate new ones
        print("[DEBUG] Some recipes were invalid, regenerating new ones...")
        return generate_recipes_with_gpt([], preferences, fresh_call=True)

    except json.JSONDecodeError as e:
        print("[ERROR] JSON parsing error:", e)
        print("[DEBUG] Raw GPT response:", response_text)
        return recipes  # Return original recipes if JSON decoding fails

    except Exception as e:
        print("[DEBUG] Error validating recipes with GPT:", e)
        return recipes  # Return original recipes on error




def generate_recipe_details_msg(recipe_info):
    """
    Build a user-friendly markdown-like message with:
      - Title
      - Servings
      - Ingredient list
      - Instructions
      - Macros
    """
    title = recipe_info.get('title', 'Untitled')
    servings = recipe_info.get('servings', 2)
    ingredients = recipe_info.get('ingredients', [])
    instructions = recipe_info.get('instructions', 'No instructions provided.')
    macros = recipe_info.get('macros', 'No macros data.')

    msg = (
        f"**{title}** (for {servings} servings)\n\n"
        f"**Ingredients:**\n"
        + "\n".join(ingredients) + "\n\n"
        f"**Instructions:**\n{instructions}\n\n"
        f"**Macros:**\n{macros}\n"
        "\nFeel free to ask more questions or choose another recipe."
    )
    return msg


def scale_ingredient(ingredient_line, scale_factor):
    """
    Naive approach: if the ingredient line starts with a number, multiply it.
    e.g., "2 cups flour" => "4 cups flour" if scale_factor=2.
    """
    pattern = r'^(\d+(\.\d+)?)\s+(.*)'
    match = re.match(pattern, ingredient_line.strip())
    if not match:
        return ingredient_line

    original_amount = float(match.group(1))
    scaled_amount = round(original_amount * scale_factor, 2)
    rest = match.group(3)
    return f"{scaled_amount} {rest}"


def scale_macros(macros_line, scale_factor):
    """
    Naive approach: If macros_line has patterns like "Calories: 100",
    multiply the numeric values by scale_factor.
    """
    parts = macros_line.split(',')
    scaled_parts = []
    for p in parts:
        p = p.strip()
        match = re.match(r'(.*?):\s*(\d+(\.\d+)?)(.*)', p)
        if match:
            label = match.group(1)
            val = float(match.group(2))
            unit = match.group(4)
            scaled_val = round(val * scale_factor, 2)
            scaled_parts.append(f"{label}: {scaled_val}{unit}")
        else:
            scaled_parts.append(p)
    return ", ".join(scaled_parts)


if __name__ == '__main__':
    app.run(debug=True)
